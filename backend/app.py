#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import zipfile
import json
import shutil
import uuid
import asyncio
from datetime import datetime
from pathlib import Path
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from werkzeug.utils import secure_filename
import magic
from local_code import LocalCodeClient
from constants import CODE_EXTENSIONS
from llm.qwen_llm import QwenLLM
from prompts.business_logic import BUSINESS_SUMMARY_PROMPT
from prompts.technical_documentation import TECHNICAL_DOCUMENTATION_PROMPT

app = Flask(__name__)
CORS(app)

# é…ç½®
app.config['MAX_CONTENT_LENGTH'] = 100 * 1024 * 1024  # 100MBé™åˆ¶
app.config['UPLOAD_FOLDER'] = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'uploads')
app.config['EXTRACTED_FOLDER'] = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'extracted')
app.config['TEMP_FOLDER'] = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'temp')
app.config['DOCS_FOLDER'] = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'docs')


def ensure_directories():
    """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
    directories = [
        app.config['UPLOAD_FOLDER'],
        app.config['EXTRACTED_FOLDER'],
        app.config['TEMP_FOLDER'],
        app.config['DOCS_FOLDER']
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        print(f"âœ… ç›®å½•å·²åˆ›å»º: {directory}")

def is_zip_file(file_path):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºZIPæ ¼å¼"""
    try:
        mime = magic.from_file(file_path, mime=True)
        return mime in ['application/zip', 'application/x-zip-compressed']
    except Exception:
        # å¦‚æœmagicåº“ä¸å¯ç”¨ï¼Œæ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        return file_path.lower().endswith('.zip')

def get_file_stats(file_path):
    """è·å–æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯"""
    stat = os.stat(file_path)
    return {
        'size': stat.st_size,
        'modified_at': datetime.fromtimestamp(stat.st_mtime).isoformat(),
        'created_at': datetime.fromtimestamp(stat.st_ctime).isoformat()
    }

def is_code_file(file_path):
    """æ£€æŸ¥æ˜¯å¦ä¸ºä»£ç æ–‡ä»¶"""
    return Path(file_path).suffix.lower() in CODE_EXTENSIONS

def get_directory_structure(directory_path, base_path=''):
    """é€’å½’è·å–ç›®å½•ç»“æ„"""
    items = []
    
    try:
        for item in os.listdir(directory_path):
            item_path = os.path.join(directory_path, item)
            relative_path = os.path.join(base_path, item)
            
            if os.path.isdir(item_path):
                # é€’å½’å¤„ç†å­ç›®å½•
                children = get_directory_structure(item_path, relative_path)
                items.append({
                    'name': item,
                    'type': 'directory',
                    'path': relative_path,
                    'children': children
                })
            else:
                # æ£€æŸ¥æ˜¯å¦ä¸ºä»£ç æ–‡ä»¶
                if is_code_file(item_path):
                    stats = get_file_stats(item_path)
                    items.append({
                        'name': item,
                        'type': 'file',
                        'path': relative_path,
                        'extension': Path(item).suffix.lower(),
                        'size': stats['size'],
                        'modified_at': stats['modified_at']
                    })
        
        # æ’åºï¼šç›®å½•åœ¨å‰ï¼Œæ–‡ä»¶åœ¨å
        items.sort(key=lambda x: (x['type'] != 'directory', x['name'].lower()))
        return items
        
    except Exception as e:
        print(f"è¯»å–ç›®å½•å¤±è´¥: {directory_path}, é”™è¯¯: {e}")
        return []

def get_all_subdirectories(directory_path):
    """è·å–ç›®å½•ä¸‹çš„æ‰€æœ‰å­ç›®å½•ï¼ŒæŒ‰æ·±åº¦æ’åºï¼ˆæœ€æ·±å±‚åœ¨å‰ï¼‰"""
    subdirs = []
    
    def collect_subdirs(path, depth=0):
        try:
            for item in os.listdir(path):
                item_path = os.path.join(path, item)
                if os.path.isdir(item_path):
                    subdirs.append((item_path, depth))
                    collect_subdirs(item_path, depth + 1)
        except Exception as e:
            print(f"è¯»å–ç›®å½•å¤±è´¥: {path}, é”™è¯¯: {e}")
    
    collect_subdirs(directory_path)
    
    # æŒ‰æ·±åº¦é™åºæ’åºï¼ˆæœ€æ·±å±‚åœ¨å‰ï¼‰
    subdirs.sort(key=lambda x: x[1], reverse=True)
    return [path for path, depth in subdirs]

def generate_documentation_for_directory(directory_path, llm_client):
    """ä¸ºæŒ‡å®šç›®å½•ç”Ÿæˆæ–‡æ¡£"""
    try:
        # åˆ›å»ºLocalCodeClientå®ä¾‹
        code_client = LocalCodeClient()
        
        # è·å–ç›®å½•ç»“æ„
        directory_structure = asyncio.run(code_client.get_directory_structure(Path(directory_path)))
        
        # è·å–ä»£ç å†…å®¹
        codebase = asyncio.run(code_client.get_all_content_from_directory(Path(directory_path)))
        
        # ç”Ÿæˆä¸šåŠ¡é€»è¾‘æ–‡æ¡£
        business_prompt = BUSINESS_SUMMARY_PROMPT.format(
            directory_structure=directory_structure,
            codebase=codebase
        )
        
        business_doc = llm_client.simple_chat(
            business_prompt,
            "æ‚¨æ˜¯ä¸€ä½æ°å‡ºçš„è½¯ä»¶æ¶æ„å¸ˆï¼Œä¸“é—¨åˆ†æä»£ç åº“çš„ä¸šåŠ¡é€»è¾‘ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§æä¾›çš„æ ¼å¼ç”Ÿæˆæ–‡æ¡£ã€‚"
        )
        
        # ç”ŸæˆæŠ€æœ¯æ–‡æ¡£
        technical_prompt = TECHNICAL_DOCUMENTATION_PROMPT.format(
            directory_structure=directory_structure,
            codebase=codebase
        )
        
        technical_doc = llm_client.simple_chat(
            technical_prompt,
            "æ‚¨æ˜¯ä¸€ä½æ°å‡ºçš„è½¯ä»¶æ¶æ„å¸ˆå’Œä¸“ä¸šæŠ€æœ¯æ–‡æ¡£æ’°å†™ä¸“å®¶ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§æä¾›çš„æ ¼å¼ç”Ÿæˆæ–‡æ¡£ã€‚"
        )
        
        return {
            'business_logic': business_doc,
            'technical_doc': technical_doc,
            'directory_structure': directory_structure,
            'codebase': codebase
        }
        
    except Exception as e:
        print(f"ç”Ÿæˆæ–‡æ¡£å¤±è´¥: {e}")
        raise e

def save_documentation(docs_data, base_docs_path, directory_name):
    """ä¿å­˜æ–‡æ¡£åˆ°æŒ‡å®šç›®å½•"""
    try:
        # åˆ›å»ºæ–‡æ¡£ç›®å½•
        doc_dir = os.path.join(base_docs_path, directory_name)
        Path(doc_dir).mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜ä¸šåŠ¡é€»è¾‘æ–‡æ¡£
        business_file = os.path.join(doc_dir, f"{directory_name}_business_logic.md")
        with open(business_file, 'w', encoding='utf-8') as f:
            f.write(docs_data['business_logic'])
        
        # ä¿å­˜æŠ€æœ¯æ–‡æ¡£
        technical_file = os.path.join(doc_dir, f"{directory_name}_technical_doc.md")
        with open(technical_file, 'w', encoding='utf-8') as f:
            f.write(docs_data['technical_doc'])
        
        return {
            'business_logic_file': business_file,
            'technical_doc_file': technical_file
        }
        
    except Exception as e:
        print(f"ä¿å­˜æ–‡æ¡£å¤±è´¥: {e}")
        raise e

@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({
        'status': 'ok',
        'timestamp': datetime.now().isoformat(),
        'upload_folder': app.config['UPLOAD_FOLDER'],
        'extracted_folder': app.config['EXTRACTED_FOLDER']
    })

@app.route('/api/upload/zip', methods=['POST'])
def upload_zip():
    """ä¸Šä¼ ZIPæ–‡ä»¶"""
    try:
        if 'zipFile' not in request.files:
            return jsonify({'error': 'è¯·é€‰æ‹©è¦ä¸Šä¼ çš„ZIPæ–‡ä»¶'}), 400
        
        file = request.files['zipFile']
        if file.filename == '':
            return jsonify({'error': 'è¯·é€‰æ‹©è¦ä¸Šä¼ çš„ZIPæ–‡ä»¶'}), 400
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        file_id = str(uuid.uuid4())
        filename = secure_filename(file.filename)
        file_extension = Path(filename).suffix
        
        if file_extension.lower() != '.zip':
            return jsonify({'error': 'åªæ”¯æŒä¸Šä¼ ZIPæ ¼å¼çš„æ–‡ä»¶'}), 400
        
        # ä¿å­˜æ–‡ä»¶
        zip_path = os.path.join(app.config['UPLOAD_FOLDER'], f"{file_id}.zip")
        file.save(zip_path)
        
        # éªŒè¯ZIPæ–‡ä»¶
        if not is_zip_file(zip_path):
            os.remove(zip_path)
            return jsonify({'error': 'æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·ä¸Šä¼ æœ‰æ•ˆçš„ZIPæ–‡ä»¶'}), 400
        
        # è§£å‹æ–‡ä»¶
        extracted_dir = os.path.join(app.config['EXTRACTED_FOLDER'], file_id)
        Path(extracted_dir).mkdir(parents=True, exist_ok=True)
        
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                # æ£€æŸ¥ZIPæ–‡ä»¶å†…å®¹
                file_list = zip_ref.namelist()
                
                if not file_list:
                    os.remove(zip_path)
                    shutil.rmtree(extracted_dir, ignore_errors=True)
                    return jsonify({'error': 'ZIPæ–‡ä»¶ä¸ºç©º'}), 400
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»£ç æ–‡ä»¶
                has_code_files = any(
                    is_code_file(name) for name in file_list 
                    if not name.endswith('/')  # æ’é™¤ç›®å½•
                )
                
                if not has_code_files:
                    os.remove(zip_path)
                    shutil.rmtree(extracted_dir, ignore_errors=True)
                    return jsonify({'error': 'ZIPæ–‡ä»¶ä¸­æœªæ‰¾åˆ°ä»£ç æ–‡ä»¶'}), 400
                
                # è§£å‹æ–‡ä»¶
                zip_ref.extractall(extracted_dir)
                
                # ç»Ÿè®¡æ–‡ä»¶ä¿¡æ¯
                total_files = len(file_list)
                code_files = len([name for name in file_list if is_code_file(name) and not name.endswith('/')])
                directories = len([name for name in file_list if name.endswith('/')])
                
                file_stats = get_file_stats(zip_path)
                
                print(f"âœ… ZIPæ–‡ä»¶è§£ææˆåŠŸ: {filename} -> {total_files}ä¸ªæ–‡ä»¶, {code_files}ä¸ªä»£ç æ–‡ä»¶")
                
                return jsonify({
                    'success': True,
                    'message': 'ZIPæ–‡ä»¶ä¸Šä¼ å¹¶è§£ææˆåŠŸ',
                    'data': {
                        'file_id': file_id,
                        'original_name': filename,
                        'file_size': file_stats['size'],
                        'extracted_path': extracted_dir,
                        'stats': {
                            'total_files': total_files,
                            'code_files': code_files,
                            'directories': directories,
                            'total_size': file_stats['size']
                        },
                        'uploaded_at': datetime.now().isoformat()
                    }
                })
                
        except zipfile.BadZipFile:
            os.remove(zip_path)
            shutil.rmtree(extracted_dir, ignore_errors=True)
            return jsonify({'error': 'ZIPæ–‡ä»¶æ ¼å¼é”™è¯¯æˆ–å·²æŸå'}), 400
            
    except Exception as e:
        print(f"æ–‡ä»¶ä¸Šä¼ å¤„ç†å¤±è´¥: {e}")
        return jsonify({'error': 'æ–‡ä»¶ä¸Šä¼ å¤±è´¥', 'message': str(e)}), 500

@app.route('/api/upload/status/<file_id>', methods=['GET'])
def get_upload_status(file_id):
    """è·å–ä¸Šä¼ çŠ¶æ€"""
    try:
        extracted_path = os.path.join(app.config['EXTRACTED_FOLDER'], file_id)
        
        if not os.path.exists(extracted_path):
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤'}), 404
        
        stats = get_file_stats(extracted_path)
        
        return jsonify({
            'success': True,
            'data': {
                'file_id': file_id,
                'exists': True,
                'extracted_at': stats['created_at'],
                'last_modified': stats['modified_at']
            }
        })
        
    except Exception as e:
        print(f"è·å–æ–‡ä»¶çŠ¶æ€å¤±è´¥: {e}")
        return jsonify({'error': 'è·å–æ–‡ä»¶çŠ¶æ€å¤±è´¥'}), 500

@app.route('/api/upload/<file_id>', methods=['DELETE'])
def delete_upload(file_id):
    """åˆ é™¤ä¸Šä¼ çš„æ–‡ä»¶"""
    try:
        zip_path = os.path.join(app.config['UPLOAD_FOLDER'], f"{file_id}.zip")
        extracted_path = os.path.join(app.config['EXTRACTED_FOLDER'], file_id)
        
        # åˆ é™¤ZIPæ–‡ä»¶
        if os.path.exists(zip_path):
            os.remove(zip_path)
        
        # åˆ é™¤è§£å‹ç›®å½•
        if os.path.exists(extracted_path):
            shutil.rmtree(extracted_path)
        
        return jsonify({
            'success': True,
            'message': 'æ–‡ä»¶åˆ é™¤æˆåŠŸ'
        })
        
    except Exception as e:
        print(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
        return jsonify({'error': 'åˆ é™¤æ–‡ä»¶å¤±è´¥'}), 500

@app.route('/api/analysis/structure/<file_id>', methods=['GET'])
def get_project_structure(file_id):
    """è·å–é¡¹ç›®ç»“æ„"""
    try:
        extracted_path = os.path.join(app.config['EXTRACTED_FOLDER'], file_id)
        
        if not os.path.exists(extracted_path):
            return jsonify({'error': 'é¡¹ç›®ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤'}), 404
        
        # è·å–ç›®å½•ç»“æ„
        structure = get_directory_structure(extracted_path)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_files = 0
        total_directories = 0
        total_size = 0
        
        def count_items(items):
            nonlocal total_files, total_directories, total_size
            for item in items:
                if item['type'] == 'directory':
                    total_directories += 1
                    if 'children' in item:
                        count_items(item['children'])
                else:
                    total_files += 1
                    total_size += item.get('size', 0)
        
        count_items(structure)
        
        return jsonify({
            'success': True,
            'data': {
                'file_id': file_id,
                'structure': structure,
                'stats': {
                    'total_files': total_files,
                    'total_directories': total_directories,
                    'total_size': total_size
                }
            }
        })
        
    except Exception as e:
        print(f"è·å–é¡¹ç›®ç»“æ„å¤±è´¥: {e}")
        return jsonify({'error': 'è·å–é¡¹ç›®ç»“æ„å¤±è´¥'}), 500

@app.route('/api/analysis/file/<file_id>', methods=['GET'])
def read_file_content(file_id):
    """è¯»å–æ–‡ä»¶å†…å®¹"""
    try:
        file_path = request.args.get('filePath')
        
        if not file_path:
            return jsonify({'error': 'ç¼ºå°‘æ–‡ä»¶è·¯å¾„å‚æ•°'}), 400
        
        extracted_path = os.path.join(app.config['EXTRACTED_FOLDER'], file_id)
        full_file_path = os.path.join(extracted_path, file_path)
        
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ–‡ä»¶è·¯å¾„åœ¨è§£å‹ç›®å½•å†…
        if not os.path.abspath(full_file_path).startswith(os.path.abspath(extracted_path)):
            return jsonify({'error': 'è®¿é—®è¢«æ‹’ç»'}), 403
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(full_file_path):
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶
        if not os.path.isfile(full_file_path):
            return jsonify({'error': 'è·¯å¾„ä¸æ˜¯æ–‡ä»¶'}), 400
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆé™åˆ¶ä¸º1MBï¼‰
        file_size = os.path.getsize(full_file_path)
        if file_size > 1024 * 1024:
            return jsonify({'error': 'æ–‡ä»¶è¿‡å¤§ï¼Œæ— æ³•è¯»å–'}), 413
        
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        file_ext = Path(full_file_path).suffix.lower()
        if file_ext not in CODE_EXTENSIONS:
            return jsonify({'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹'}), 400
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        try:
            with open(full_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            # å¦‚æœUTF-8è§£ç å¤±è´¥ï¼Œå°è¯•å…¶ä»–ç¼–ç 
            try:
                with open(full_file_path, 'r', encoding='gbk') as f:
                    content = f.read()
            except UnicodeDecodeError:
                return jsonify({'error': 'æ–‡ä»¶ç¼–ç ä¸æ”¯æŒ'}), 400
        
        stats = get_file_stats(full_file_path)
        
        return jsonify({
            'success': True,
            'data': {
                'file_id': file_id,
                'file_path': file_path,
                'file_name': Path(full_file_path).name,
                'extension': file_ext,
                'size': file_size,
                'content': content,
                'modified_at': stats['modified_at'],
                'lines': len(content.split('\n'))
            }
        })
        
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return jsonify({'error': 'è¯»å–æ–‡ä»¶å¤±è´¥'}), 500

@app.route('/api/analysis/search/<file_id>', methods=['GET'])
def search_files(file_id):
    """æœç´¢æ–‡ä»¶"""
    try:
        query = request.args.get('query')
        extension = request.args.get('extension')
        
        if not query:
            return jsonify({'error': 'æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º'}), 400
        
        extracted_path = os.path.join(app.config['EXTRACTED_FOLDER'], file_id)
        
        if not os.path.exists(extracted_path):
            return jsonify({'error': 'é¡¹ç›®ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤'}), 404
        
        results = []
        
        def search_files_recursive(dir_path, base_path=''):
            try:
                for item in os.listdir(dir_path):
                    item_path = os.path.join(dir_path, item)
                    relative_path = os.path.join(base_path, item)
                    
                    if os.path.isdir(item_path):
                        search_files_recursive(item_path, relative_path)
                    else:
                        file_ext = Path(item).suffix.lower()
                        
                        # æ£€æŸ¥æ‰©å±•åè¿‡æ»¤
                        if extension and file_ext != extension.lower():
                            continue
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸ºä»£ç æ–‡ä»¶
                        if file_ext not in CODE_EXTENSIONS:
                            continue
                        
                        # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ¹é…
                        if query.lower() in item.lower():
                            stats = get_file_stats(item_path)
                            results.append({
                                'name': item,
                                'path': relative_path,
                                'extension': file_ext,
                                'size': stats['size'],
                                'modified_at': stats['modified_at']
                            })
            except Exception as e:
                print(f"æœç´¢ç›®å½•å¤±è´¥: {dir_path}, é”™è¯¯: {e}")
        
        search_files_recursive(extracted_path)
        
        return jsonify({
            'success': True,
            'data': {
                'file_id': file_id,
                'query': query,
                'extension': extension,
                'results': results,
                'total_results': len(results)
            }
        })
        
    except Exception as e:
        print(f"æœç´¢æ–‡ä»¶å¤±è´¥: {e}")
        return jsonify({'error': 'æœç´¢æ–‡ä»¶å¤±è´¥'}), 500

@app.route('/api/analysis/stats/<file_id>', methods=['GET'])
def get_project_stats(file_id):
    """è·å–é¡¹ç›®ç»Ÿè®¡ä¿¡æ¯"""
    try:
        extracted_path = os.path.join(app.config['EXTRACTED_FOLDER'], file_id)
        
        if not os.path.exists(extracted_path):
            return jsonify({'error': 'é¡¹ç›®ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤'}), 404
        
        stats = {
            'total_files': 0,
            'total_directories': 0,
            'total_size': 0,
            'extensions': {},
            'largest_files': []
        }
        
        def collect_stats_recursive(dir_path):
            try:
                for item in os.listdir(dir_path):
                    item_path = os.path.join(dir_path, item)
                    
                    if os.path.isdir(item_path):
                        stats['total_directories'] += 1
                        collect_stats_recursive(item_path)
                    else:
                        file_ext = Path(item).suffix.lower()
                        
                        if file_ext in CODE_EXTENSIONS:
                            stats['total_files'] += 1
                            
                            file_size = os.path.getsize(item_path)
                            stats['total_size'] += file_size
                            
                            # ç»Ÿè®¡æ‰©å±•å
                            stats['extensions'][file_ext] = stats['extensions'].get(file_ext, 0) + 1
                            
                            # è®°å½•å¤§æ–‡ä»¶
                            relative_path = os.path.relpath(item_path, extracted_path)
                            stats['largest_files'].append({
                                'name': item,
                                'path': relative_path,
                                'size': file_size,
                                'extension': file_ext
                            })
            except Exception as e:
                print(f"ç»Ÿè®¡ç›®å½•å¤±è´¥: {dir_path}, é”™è¯¯: {e}")
        
        collect_stats_recursive(extracted_path)
        
        # æ’åºæ‰©å±•åç»Ÿè®¡
        sorted_extensions = sorted(
            stats['extensions'].items(), 
            key=lambda x: x[1], 
            reverse=True
        )
        stats['extensions'] = [{'extension': ext, 'count': count} for ext, count in sorted_extensions]
        
        # æ’åºå¤§æ–‡ä»¶
        stats['largest_files'].sort(key=lambda x: x['size'], reverse=True)
        stats['largest_files'] = stats['largest_files'][:10]  # åªä¿ç•™å‰10ä¸ª
        
        return jsonify({
            'success': True,
            'data': {
                'file_id': file_id,
                'stats': stats
            }
        })
        
    except Exception as e:
        print(f"è·å–é¡¹ç›®ç»Ÿè®¡å¤±è´¥: {e}")
        return jsonify({'error': 'è·å–é¡¹ç›®ç»Ÿè®¡å¤±è´¥'}), 500

@app.route('/api/analysis/generate-docs/<file_id>', methods=['POST'])
def generate_documentation(file_id):
    """ç”Ÿæˆä»£ç æ–‡æ¡£æ¥å£"""
    try:
        # æ£€æŸ¥Content-Type
        if not request.is_json:
            return jsonify({
                'error': 'è¯·æ±‚æ ¼å¼é”™è¯¯',
                'message': 'è¯·è®¾ç½®Content-Typeä¸ºapplication/json'
            }), 415
        
        # è·å–è¯·æ±‚å‚æ•°
        data = request.get_json() or {}
        start_directory = data.get('start_directory', '')  # å¯é€‰çš„èµ·å§‹ç›®å½•
        
        # éªŒè¯æ–‡ä»¶ID
        extracted_path = os.path.join(app.config['EXTRACTED_FOLDER'], file_id)
        if not os.path.exists(extracted_path):
            return jsonify({'error': 'é¡¹ç›®ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤'}), 404
        
        # ç¡®å®šèµ·å§‹ç›®å½•
        if start_directory:
            start_path = os.path.join(extracted_path, start_directory)
            if not os.path.exists(start_path) or not os.path.isdir(start_path):
                return jsonify({'error': 'æŒ‡å®šçš„èµ·å§‹ç›®å½•ä¸å­˜åœ¨'}), 400
        else:
            start_path = extracted_path
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        try:
            llm_client = QwenLLM()
        except Exception as e:
            return jsonify({'error': f'LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}'}), 500
        
        # è·å–æ‰€æœ‰å­ç›®å½•ï¼ˆæŒ‰æ·±åº¦é™åºæ’åºï¼‰
        subdirectories = get_all_subdirectories(start_path)
        
        # æ·»åŠ èµ·å§‹ç›®å½•æœ¬èº«
        all_directories = [start_path] + subdirectories
        
        results = []
        total_directories = len(all_directories)
        
        for i, directory_path in enumerate(all_directories):
            try:
                directory_name = os.path.basename(directory_path)
                relative_path = os.path.relpath(directory_path, extracted_path)
                
                print(f"ğŸ“ æ­£åœ¨å¤„ç†ç›®å½• ({i+1}/{total_directories}): {relative_path}")
                
                # æ£€æŸ¥ç›®å½•æ˜¯å¦åŒ…å«ä»£ç æ–‡ä»¶
                code_files = []
                for root, dirs, files in os.walk(directory_path):
                    for file in files:
                        if is_code_file(os.path.join(root, file)):
                            code_files.append(file)
                
                if not code_files:
                    print(f"âš ï¸ ç›®å½• {relative_path} ä¸åŒ…å«ä»£ç æ–‡ä»¶ï¼Œè·³è¿‡")
                    continue
                
                # ç”Ÿæˆæ–‡æ¡£
                docs_data = generate_documentation_for_directory(directory_path, llm_client)
                
                # ä¿å­˜æ–‡æ¡£
                saved_files = save_documentation(docs_data, app.config['DOCS_FOLDER'], directory_name)
                
                results.append({
                    'directory_name': directory_name,
                    'relative_path': relative_path,
                    'code_files_count': len(code_files),
                    'files': saved_files,
                    'status': 'success'
                })
                
                print(f"âœ… ç›®å½• {relative_path} æ–‡æ¡£ç”Ÿæˆå®Œæˆ")
                
            except Exception as e:
                print(f"âŒ å¤„ç†ç›®å½• {directory_path} å¤±è´¥: {e}")
                results.append({
                    'directory_name': os.path.basename(directory_path),
                    'relative_path': os.path.relpath(directory_path, extracted_path),
                    'error': str(e),
                    'status': 'error'
                })
        
        # ç»Ÿè®¡ç»“æœ
        success_count = len([r for r in results if r['status'] == 'success'])
        error_count = len([r for r in results if r['status'] == 'error'])
        
        return jsonify({
            'success': True,
            'message': f'æ–‡æ¡£ç”Ÿæˆå®Œæˆï¼ŒæˆåŠŸå¤„ç† {success_count} ä¸ªç›®å½•ï¼Œå¤±è´¥ {error_count} ä¸ª',
            'data': {
                'file_id': file_id,
                'start_directory': start_directory or 'root',
                'total_directories': total_directories,
                'success_count': success_count,
                'error_count': error_count,
                'results': results,
                'docs_base_path': app.config['DOCS_FOLDER']
            }
        })
        
    except Exception as e:
        print(f"ç”Ÿæˆæ–‡æ¡£æ¥å£å¤±è´¥: {e}")
        return jsonify({'error': 'ç”Ÿæˆæ–‡æ¡£å¤±è´¥', 'message': str(e)}), 500

@app.route('/api/analysis/docs/<file_id>', methods=['GET'])
def get_generated_docs(file_id):
    """è·å–ç”Ÿæˆçš„æ–‡æ¡£åˆ—è¡¨"""
    try:
        docs_path = app.config['DOCS_FOLDER']
        
        if not os.path.exists(docs_path):
            return jsonify({
                'success': True,
                'data': {
                    'file_id': file_id,
                    'docs': [],
                    'total_docs': 0
                }
            })
        
        docs = []
        for item in os.listdir(docs_path):
            item_path = os.path.join(docs_path, item)
            if os.path.isdir(item_path):
                doc_files = []
                for file in os.listdir(item_path):
                    if file.endswith('.md'):
                        file_path = os.path.join(item_path, file)
                        stats = get_file_stats(file_path)
                        doc_files.append({
                            'name': file,
                            'path': file_path,
                            'size': stats['size'],
                            'modified_at': stats['modified_at']
                        })
                
                if doc_files:
                    docs.append({
                        'directory_name': item,
                        'files': doc_files
                    })
        
        return jsonify({
            'success': True,
            'data': {
                'file_id': file_id,
                'docs': docs,
                'total_docs': len(docs)
            }
        })
        
    except Exception as e:
        print(f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}")
        return jsonify({'error': 'è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥'}), 500

@app.route('/api/analysis/docs/<file_id>/<directory_name>/<filename>', methods=['GET'])
def download_doc(file_id, directory_name, filename):
    """ä¸‹è½½ç”Ÿæˆçš„æ–‡æ¡£"""
    try:
        doc_path = os.path.join(app.config['DOCS_FOLDER'], directory_name, filename)
        
        if not os.path.exists(doc_path):
            return jsonify({'error': 'æ–‡æ¡£ä¸å­˜åœ¨'}), 404
        
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ–‡ä»¶è·¯å¾„åœ¨docsç›®å½•å†…
        if not os.path.abspath(doc_path).startswith(os.path.abspath(app.config['DOCS_FOLDER'])):
            return jsonify({'error': 'è®¿é—®è¢«æ‹’ç»'}), 403
        
        return send_from_directory(
            os.path.dirname(doc_path),
            os.path.basename(doc_path),
            as_attachment=True,
            download_name=filename
        )
        
    except Exception as e:
        print(f"ä¸‹è½½æ–‡æ¡£å¤±è´¥: {e}")
        return jsonify({'error': 'ä¸‹è½½æ–‡æ¡£å¤±è´¥'}), 500

@app.errorhandler(413)
def too_large(e):
    return jsonify({'error': 'æ–‡ä»¶è¿‡å¤§'}), 413

@app.errorhandler(404)
def not_found(e):
    return jsonify({'error': 'æ¥å£ä¸å­˜åœ¨'}), 404

@app.errorhandler(500)
def internal_error(e):
    return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500


if __name__ == '__main__':
    ensure_directories()
    print("ğŸš€ Pythonåç«¯æœåŠ¡å™¨å¯åŠ¨ä¸­...")
    print(f"ğŸ“ ä¸Šä¼ ç›®å½•: {app.config['UPLOAD_FOLDER']}")
    print(f"ğŸ“ è§£å‹ç›®å½•: {app.config['EXTRACTED_FOLDER']}")
    print(f"ğŸ“ ä¸´æ—¶ç›®å½•: {app.config['TEMP_FOLDER']}")
    print(f"ğŸ“ æ–‡æ¡£ç›®å½•: {app.config['DOCS_FOLDER']}")
    
    app.run(host='0.0.0.0', port=3001, debug=True) 